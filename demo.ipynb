{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio  # recording and running an audio file\n",
    "import whisper  # for speech2text\n",
    "import wave     # to write the audio as WAV file\n",
    "import os       # file management\n",
    "import openai   # for GPT3 \n",
    "import requests # to handle timeout of the API call"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record and Save Audio File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Recording from microphone\n",
    "CHANNELS = 1    # mono/stereo\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100    # Hz\n",
    "CHUNK = 1024    \n",
    "TEMP_AUDIO_FILE_PATH = \"./temp.wav\"\n",
    "DURATION = 20    # seconds of recording\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORD FROM MICROPHONE\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "print(\"Recording in progress...\")\n",
    "frames = [] # list of all audio chunks.\n",
    "\n",
    "# Each chunk is 1024 samples.\n",
    "# so every second we get 44100 / 1024 ~ 43 chunks.\n",
    "# so for 5 seconds, we have to record 43*5 chunks.\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * DURATION)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "stream.stop_stream()\n",
    "print(\"Recording stopped.\")\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "print(\"Writing Audio File...\")\n",
    "with wave.open(TEMP_AUDIO_FILE_PATH, 'wb') as wf:\n",
    "    wf.setparams((CHANNELS, p.get_sample_size(FORMAT), RATE, 0, 'NONE', 'NONE'))\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "print(f\"Audio File Written: {TEMP_AUDIO_FILE_PATH}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Example:\n",
    "For example, set the `DURATION` to 20 seconds and read this out:\n",
    "\n",
    "\"If, however, the existence of evil is to be consistently explained as a necessary condition for the realization of certain kinds of good, then the kind of good that requires the existence of evil must be identified and shown to be such that it could not be realized in a world without evil.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\") # transcribes the audio file\n",
    "result = model.transcribe(TEMP_AUDIO_FILE_PATH)\n",
    "text = result[\"text\"]\n",
    "print(f\"Transcription of {TEMP_AUDIO_FILE_PATH} :\")\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the transcription\n",
    "\n",
    "[Prompt engineering is an important aspect of interacting with Large Language Models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt = (f\"Summarize this text: {text}\")\n",
    "# prompt = (f\"Summarize this text in fewer words: {text}\")\n",
    "# prompt = (f\"Summarize this text in fewer and simpler words: {text}\")\n",
    "prompt = (f\"Explain this text in simpler words: {text}\")\n",
    "\n",
    "# Call GPT3\n",
    "try:\n",
    "    openai_output = openai.Completion.create(\n",
    "        engine = \"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.6,\n",
    "        timeout=10\n",
    "        )\n",
    "    print(\"openAI.completion created\")\n",
    "except requests.exceptions.ReadTimeout:\n",
    "    print(\"Timeout: openAI.Completion took too long to respond\")\n",
    "    openai_output = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary\n",
    "summary = openai_output.choices[0].text\n",
    "\n",
    "print(\"Summary/Explanation:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b5412b3d367081c5518987b911806b9082cedff759411547831ddb9d68fd1e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
